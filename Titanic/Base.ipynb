{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ PassengerId\n",
    "df.drop(columns=['PassengerId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–æ–ª–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—Ä—É—á–Ω—É—é –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "df.loc[df['Name'].str.contains('Icard, Miss. Amelie'), 'Embarked'] = 'C'  # –®–µ—Ä–±—É—Ä\n",
    "df.loc[df['Name'].str.contains('Stone, Mrs. George Nelson'), 'Embarked'] = 'S'  # –°–∞—É—Ç–≥–µ–º–ø—Ç–æ–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º imputer –∫ –¥–∞–Ω–Ω—ã–º\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π –≤ Embarked\n",
    "embarked_counts = df['Embarked'].value_counts()\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ Embarked –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏\n",
    "df['Embarked'] = df['Embarked'].map(embarked_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–Ω–∏–º–∞–µ–º—ã—Ö –∫–∞—é—Ç\n",
    "df['Cabin_Count'] = df['Cabin'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–∞—é—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã\n",
    "# cabin_letters_only = df[df['Cabin'].notna() & df['Cabin'].str.match(r'^[A-Za-z]+$', na=False)]\n",
    "\n",
    "# # –í—ã–≤–æ–¥ —Å—Ç–æ–ª–±—Ü–æ–≤ Name –∏ Cabin\n",
    "# print(cabin_letters_only[['Name', 'Cabin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã –∫–∞—é—Ç—ã\n",
    "df['Cabin_Letter'] = df['Cabin'].str.extract('([A-Za-z])')\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ Cabin\n",
    "df.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–º –Ω–æ–º–µ—Ä –∫–∞—é—Ç—ã –∏ –∑–∞–∫–æ–Ω–¥–∏—Ä—É–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏—Ç—É–ª–∞ (–æ–±—Ä–∞—â–µ–Ω–∏—è) –∏–∑ –∏–º–µ–Ω–∏\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "\n",
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–º–∏–ª–∏–∏\n",
    "df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ Name\n",
    "df = df.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ Title\n",
    "df['Title'] = df['Title'].astype('category').cat.codes\n",
    "\n",
    "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ Surname\n",
    "df['Surname'] = df['Surname'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è \"0\" (—Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é)\n",
    "df['Cabin_Letter'] = df['Cabin_Letter'].fillna('0')\n",
    "\n",
    "# One-Hot Encoding –¥–ª—è Cabin_Letter\n",
    "df = pd.get_dummies(df, columns=['Cabin_Letter'], prefix='Cabin', dtype=int)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "print(df.head())\n",
    "\n",
    "# –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏—Å—Ö–æ–¥–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü —É–¥–∞–ª–µ–Ω\n",
    "if 'Cabin_Letter' in df.columns:\n",
    "    df.drop(columns=['Cabin_Letter'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=[0, 1, 2, 3, 4]).astype(float)\n",
    "df['FarePerPerson'] = df['Fare'] / df['FamilySize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \n",
    "            'Cabin_Count', 'Title', 'Surname', 'Cabin_A', 'Cabin_B', 'Cabin_C', \n",
    "            'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_T',\n",
    "            'FamilySize', 'IsAlone', 'AgeGroup', 'FarePerPerson']\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ `Cabin_0` = NaN (–µ—Å–ª–∏ —Ç–∞–∫–∏–µ –µ—Å—Ç—å)\n",
    "df = df.dropna(subset=['Cabin_0'])\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â–∏–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ\n",
    "X = df[features]\n",
    "y = df['Cabin_0']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å RandomForest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy:.4f}')\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ `Cabin_0` —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "df.loc[df['Cabin_0'] == 0, 'Cabin_0'] = model.predict(df.loc[df['Cabin_0'] == 0, features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \n",
    "            'Cabin_Count', 'Title', 'Surname', 'Cabin_0', 'Cabin_A', 'Cabin_B', \n",
    "            'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_T']\n",
    "\n",
    "X = df[features]  # –î–∞–Ω–Ω—ã–µ (–ø—Ä–∏–∑–Ω–∞–∫–∏)\n",
    "y = df['Survived']  # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=200, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=200, random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=200, random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# –û–±—É—á–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results[name] = accuracy  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "\n",
    "        print(f\"\\nüîπ {name}\")\n",
    "        print(f\"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –≤ {name}: {e}\")\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# –í—ã–≤–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "best_model_name, best_accuracy = sorted_results[0]\n",
    "print(f\"\\n‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_accuracy:.4f}\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø–æ—Ä—è–¥–∫–µ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "print(\"\\nüìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π (–æ—Ç –ª—É—á—à–µ–π –∫ —Ö—É–¥—à–µ–π):\")\n",
    "for name, acc in sorted_results:\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ test.csv —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º PassengerId\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º PassengerId –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "passenger_ids = test_df['PassengerId']\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ –∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫ test_df\n",
    "test_df.drop(columns=['PassengerId', 'Ticket'], inplace=True)\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
    "test_df['Embarked'] = test_df['Embarked'].map(embarked_counts)\n",
    "test_df[['Age']] = imputer.transform(test_df[['Age']])\n",
    "test_df['Cabin_Count'] = test_df['Cabin'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 1)\n",
    "test_df['Cabin_Letter'] = test_df['Cabin'].str.extract('([A-Za-z])')\n",
    "test_df.drop(columns=['Cabin'], inplace=True)\n",
    "test_df['Title'] = test_df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "test_df['Surname'] = test_df['Name'].str.split(',').str[0]\n",
    "test_df.drop(columns=['Name'], inplace=True)\n",
    "test_df['Title'] = test_df['Title'].astype('category').cat.codes\n",
    "test_df['Surname'] = test_df['Surname'].astype('category').cat.codes\n",
    "test_df['Cabin_Letter'] = test_df['Cabin_Letter'].fillna('0')\n",
    "test_df = pd.get_dummies(test_df, columns=['Cabin_Letter'], prefix='Cabin', dtype=int)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å\n",
    "for col in df.columns:\n",
    "    if col not in test_df.columns:\n",
    "        test_df[col] = 0  \n",
    "\n",
    "# –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç\n",
    "test_df = test_df[X.columns]\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–∂–∏–≤–∞–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é (Random Forest / CatBoost / XGBoost / LightGBM)\n",
    "best_model = model  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –Ω–∞–ø—Ä–∏–º–µ—Ä: best_model = catboost_model\n",
    "test_df['Survived'] = best_model.predict(test_df)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ gender_submission.csv\n",
    "submission = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': test_df['Survived']})\n",
    "submission.to_csv(\"gender_submission.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ –§–∞–π–ª gender_submission.csv —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
