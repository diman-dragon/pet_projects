{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем столбец 'Title' удаляя точки после титулов\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')[0]\n",
    "\n",
    "# Удаление столбца PassengerId\n",
    "df.drop(columns=['PassengerId'], inplace=True)\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1}).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:84: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:84: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\14488\\AppData\\Local\\Temp\\ipykernel_11928\\362483581.py:84: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Cabin_Number'] = df['Primary_Cabin'].str.extract('(\\d+)').astype(float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'PC 17610'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11928\\362483581.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;31m# Шаг 4: Обучение модели (например, случайный лес)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# Шаг 5: Оценка модели\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         X, y = validate_data(\n\u001b[0m\u001b[0;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2957\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2961\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1052\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n\u001b[0;32m   1058\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'PC 17610'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Вручную заполняем пропущенные значения\n",
    "df.loc[df['Name'].str.contains('Icard, Miss. Amelie'), 'Embarked'] = 'C'  # Шербур\n",
    "df.loc[df['Name'].str.contains('Stone, Mrs. George Nelson'), 'Embarked'] = 'S'  # Саутгемптон\n",
    "# Создаём объект KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Применяем imputer к данным\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Pclass'], dtype=np.int8)\n",
    "# Define age group boundaries and labels\n",
    "age_bins = [0, 1, 5, 10, 14, 18, 30, 50, 70, df['Age'].max()]\n",
    "age_labels = [\n",
    "    \"Infant\", \n",
    "    \"Toddler\", \n",
    "    \"Child\", \n",
    "    \"Young_Teen\", \n",
    "    \"Teenager\", \n",
    "    \"Young_Adult\", \n",
    "    \"Adult\", \n",
    "    \"Senior\", \n",
    "    \"Elderly\"\n",
    "]\n",
    "\n",
    "# Create a new column with age groups\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "df = pd.get_dummies(df, columns=['AgeGroup'], prefix='AgeGroup', dtype=np.int8)\n",
    "# Создание нового признака FamilySize\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Признак одиночного пассажира\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(np.int8)\n",
    "\n",
    "# Стоимость билета на человека\n",
    "df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "# Извлечение титула (обращения) из имени\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "\n",
    "# Удаление титула из Name\n",
    "df['Name'] = df['Name'].str.replace(r' [A-Za-z]+\\.', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "# Маппинг титулов\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr',\n",
    "    'Miss': 'Miss',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Master': 'Master',\n",
    "    'Dr': 'Rare',\n",
    "    'Rev': 'Rare',\n",
    "    'Mlle': 'Miss',\n",
    "    'Major': 'Rare',\n",
    "    'Col': 'Rare',\n",
    "    'Countess': 'Noble',\n",
    "    'Capt': 'Rare',\n",
    "    'Ms': 'Miss',\n",
    "    'Sir': 'Noble',\n",
    "    'Lady': 'Noble',\n",
    "    'Mme': 'Mrs',\n",
    "    'Don': 'Noble',\n",
    "    'Jonkheer': 'Noble'\n",
    "}\n",
    "\n",
    "# Применяем маппинг к титулу в обучающем наборе\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "df['Title'] = df['Title'].map(title_mapping).fillna('Rare')  # Пропущенные значения заменяем на 'Rare'\n",
    "\n",
    "# Инициализация LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных титулов, включая 'Rare'\n",
    "le.fit(df['Title'].unique())\n",
    "\n",
    "# Преобразуем титулы в числовые значения\n",
    "df['Title'] = le.transform(df['Title'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Name'] = le.fit_transform(df['Name'].str.split(',').str[0])  # Кодируем только фамилию\n",
    "# Создаем признак количества кают\n",
    "df['Cabin_Count'] = df['Cabin'].str.split().str.len().fillna(1)\n",
    "# Разделяем множественные каюты и берем первую\n",
    "df['Primary_Cabin'] = df['Cabin'].str.split().str[0]\n",
    "# Разделяем номер основной каюты на букву и число\n",
    "df['Cabin_Letter'] = df['Primary_Cabin'].str[0]\n",
    "df['Cabin_Number'] = df['Primary_Cabin'].str.extract('(\\d+)').astype(float)\n",
    "df.filter(like='Cabin', axis=1)\n",
    "\n",
    "# Удаление столбца Primary_Cabin\n",
    "df.drop(columns=['Primary_Cabin','Cabin'], inplace=True)\n",
    "# Разделение данных на train и test (train - с известными Cabin_Letter, test - с NaN)\n",
    "train_df_Cabin_Letter = df.dropna(subset=['Cabin_Letter'])\n",
    "\n",
    "# Формирование test_df для строк, где 'Cabin_Letter' содержит NaN\n",
    "test_df_Cabin_Letter = df[df['Cabin_Letter'].isna()]  # строки с NaN в 'Cabin_Letter'\n",
    "# Шаг 1: Подготовка данных\n",
    "X = train_df_Cabin_Letter.drop(columns=['Cabin_Letter'])  # Убираем целевой столбец и 'Cabin'\n",
    "y = train_df_Cabin_Letter['Cabin_Letter']  # Целевая переменная\n",
    "\n",
    "# Шаг 3: Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Шаг 4: Обучение модели (например, случайный лес)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Шаг 5: Оценка модели\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Точность модели: {accuracy:.4f}\")\n",
    "# Шаг 1: Подготовка данных для тестовой выборки\n",
    "X_test_df_Cabin_Letter = test_df_Cabin_Letter.drop(columns=['Cabin_Letter'])  # Убираем целевой столбец и 'Cabin'\n",
    "\n",
    "# Шаг 2: Предсказания для test_df_Cabin_Letter\n",
    "predictions = model.predict(X_test_df_Cabin_Letter)\n",
    "\n",
    "# Шаг 3: Запись предсказаний в основной столбец 'Cabin_Letter'\n",
    "df.loc[test_df_Cabin_Letter.index, 'Cabin_Letter'] = predictions\n",
    "\n",
    "\n",
    "# Кодируем титулы с помощью LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Cabin_Letter'] = le.fit_transform(df['Cabin_Letter'])\n",
    "# Заполняем пропуски медианой\n",
    "median_cabin = df['Cabin_Number'].median()\n",
    "df['Cabin_Number'].fillna(median_cabin, inplace=True)\n",
    "# Определяем столбцы с бинарными значениями (0 и 1)\n",
    "binary_columns = [col for col in df.columns if set(df[col].dropna()) <= {0, 1}]\n",
    "\n",
    "# Столбцы, которые нужно нормализовать (не бинарные)\n",
    "columns_to_normalize = [col for col in df.columns if col not in binary_columns]\n",
    "\n",
    "# Инициализация MinMaxScaler для нормализации\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Нормализуем только числовые столбцы (не бинарные)\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "# Разделим данные на признаки (X) и целевую переменную (y)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Инициализация моделей\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(silent=True, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1, max_depth=5, num_leaves=31)  # ограничение max_depth и num_leaves\n",
    "}\n",
    "\n",
    "# Оценка всех моделей\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Обучение модели\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания на тестовых данных\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Оценка метрик модели\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    full_precision = precision_score(y_test, y_pred, average='binary')  # Точность по всем данным\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Full Precision': full_precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Преобразуем результаты в DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Выводим таблицу с результатами\n",
    "print(results_df)\n",
    "\n",
    "# Сохраняем лучшую модель (по Full Precision или другой метрике, если нужно)\n",
    "best_model_name = results_df.loc[results_df['Accuracy'].idxmax(), 'Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Сохраняем модель\n",
    "joblib.dump(best_model, f\"{best_model_name}_model.pkl\")\n",
    "\n",
    "print(f\"Лучшая модель: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка тестовых данных для предсказания\n",
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем столбец 'Title' удаляя точки после титулов\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Pclass', 'SibSp', 'Parch']] = df[['Pclass', 'SibSp', 'Parch']].astype('int8')\n",
    "\n",
    "# Удаление столбца PassengerId\n",
    "df.drop(columns=['Ticket'], inplace=True)\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1}).astype(\"int8\")\n",
    "# Вручную заполняем пропущенные значения\n",
    "df.loc[df['Name'].str.contains('Icard, Miss. Amelie'), 'Embarked'] = 'C'  # Шербур\n",
    "df.loc[df['Name'].str.contains('Stone, Mrs. George Nelson'), 'Embarked'] = 'S'  # Саутгемптон\n",
    "# Создаём объект KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Применяем imputer к данным\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Pclass'], dtype=np.int8)\n",
    "# Define age group boundaries and labels\n",
    "age_bins = [0, 1, 5, 10, 14, 18, 30, 50, 70, df['Age'].max()]\n",
    "age_labels = [\n",
    "    \"Infant\", \n",
    "    \"Toddler\", \n",
    "    \"Child\", \n",
    "    \"Young_Teen\", \n",
    "    \"Teenager\", \n",
    "    \"Young_Adult\", \n",
    "    \"Adult\", \n",
    "    \"Senior\", \n",
    "    \"Elderly\"\n",
    "]\n",
    "\n",
    "# Create a new column with age groups\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "df = pd.get_dummies(df, columns=['AgeGroup'], prefix='AgeGroup', dtype=np.int8)\n",
    "# Создание нового признака FamilySize\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Признак одиночного пассажира\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(np.int8)\n",
    "\n",
    "# Стоимость билета на человека\n",
    "df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "# Извлечение титула (обращения) из имени\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "\n",
    "# Удаление титула из Name\n",
    "df['Name'] = df['Name'].str.replace(r' [A-Za-z]+\\.', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "# Маппинг титулов\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr',\n",
    "    'Miss': 'Miss',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Master': 'Master',\n",
    "    'Dr': 'Rare',\n",
    "    'Rev': 'Rare',\n",
    "    'Mlle': 'Miss',\n",
    "    'Major': 'Rare',\n",
    "    'Col': 'Rare',\n",
    "    'Countess': 'Noble',\n",
    "    'Capt': 'Rare',\n",
    "    'Ms': 'Miss',\n",
    "    'Sir': 'Noble',\n",
    "    'Lady': 'Noble',\n",
    "    'Mme': 'Mrs',\n",
    "    'Don': 'Noble',\n",
    "    'Jonkheer': 'Noble'\n",
    "}\n",
    "\n",
    "# Применяем маппинг к титулу в обучающем наборе\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "df['Title'] = df['Title'].map(title_mapping).fillna('Rare')  # Пропущенные значения заменяем на 'Rare'\n",
    "\n",
    "# Инициализация LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных титулов, включая 'Rare'\n",
    "le.fit(df['Title'].unique())\n",
    "\n",
    "# Преобразуем титулы в числовые значения\n",
    "df['Title'] = le.transform(df['Title'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Name'] = le.fit_transform(df['Name'].str.split(',').str[0])  # Кодируем только фамилию\n",
    "# Создаем признак количества кают\n",
    "df['Cabin_Count'] = df['Cabin'].str.split().str.len().fillna(1)\n",
    "# Разделяем множественные каюты и берем первую\n",
    "df['Primary_Cabin'] = df['Cabin'].str.split().str[0]\n",
    "# Разделяем номер основной каюты на букву и число\n",
    "df['Cabin_Letter'] = df['Primary_Cabin'].str[0]\n",
    "df['Cabin_Number'] = df['Primary_Cabin'].str.extract('(\\d+)').astype(float)\n",
    "df.filter(like='Cabin', axis=1)\n",
    "\n",
    "# Удаление столбца Primary_Cabin\n",
    "df.drop(columns=['Primary_Cabin','Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на train и test (train - с известными Cabin_Letter, test - с NaN)\n",
    "train_df_Cabin_Letter = df.dropna(subset=['Cabin_Letter'])\n",
    "\n",
    "# Формирование test_df для строк, где 'Cabin_Letter' содержит NaN\n",
    "test_df_Cabin_Letter = df[df['Cabin_Letter'].isna()]  # строки с NaN в 'Cabin_Letter'\n",
    "# Шаг 1: Подготовка данных\n",
    "X = train_df_Cabin_Letter.drop(columns=['Cabin_Letter'])  # Убираем целевой столбец и 'Cabin'\n",
    "y = train_df_Cabin_Letter['Cabin_Letter']  # Целевая переменная\n",
    "\n",
    "# Шаг 3: Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Шаг 4: Обучение модели (например, случайный лес)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Шаг 5: Оценка модели\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Точность модели: {accuracy:.4f}\")\n",
    "# Шаг 1: Подготовка данных для тестовой выборки\n",
    "X_test_df_Cabin_Letter = test_df_Cabin_Letter.drop(columns=['Cabin_Letter'])  # Убираем целевой столбец и 'Cabin'\n",
    "\n",
    "# Шаг 2: Предсказания для test_df_Cabin_Letter\n",
    "predictions = model.predict(X_test_df_Cabin_Letter)\n",
    "\n",
    "# Шаг 3: Запись предсказаний в основной столбец 'Cabin_Letter'\n",
    "df.loc[test_df_Cabin_Letter.index, 'Cabin_Letter'] = predictions\n",
    "\n",
    "\n",
    "# Кодируем титулы с помощью LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Cabin_Letter'] = le.fit_transform(df['Cabin_Letter'])\n",
    "# Заполняем пропуски медианой\n",
    "median_cabin = df['Cabin_Number'].median()\n",
    "df['Cabin_Number'].fillna(median_cabin, inplace=True)\n",
    "# Определяем столбцы с бинарными значениями (0 и 1)\n",
    "binary_columns = [col for col in df.columns if set(df[col].dropna()) <= {0, 1}]\n",
    "\n",
    "# Столбцы, которые нужно нормализовать (не бинарные), исключая 'PassengerId'\n",
    "columns_to_normalize = [col for col in df.columns if col not in binary_columns and col != 'PassengerId']\n",
    "\n",
    "\n",
    "# Инициализация MinMaxScaler для нормализации\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Нормализуем только числовые столбцы (не бинарные)\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверить наличие пропущенных значений в DataFrame\n",
    "nan_check = df.isna().sum()\n",
    "\n",
    "# Выводим количество пропущенных значений по каждому столбцу\n",
    "print(nan_check)\n",
    "# Заполняем пропущенные значения медианой по каждому столбцу\n",
    "df = df.apply(lambda col: col.fillna(col.median()) if col.isna().sum() > 0 else col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогнозируем выживаемость\n",
    "X_test = df.drop('PassengerId', axis=1)\n",
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результат\n",
    "submission = pd.DataFrame({'PassengerId': df['PassengerId'], 'Survived': y_pred_test})\n",
    "submission.to_csv('gender_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
